{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "gdDOGZZ7zZK9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack as sp_hstack\n",
    "from scipy.sparse import diags as spdiags\n",
    "from scipy.sparse import eye as speye\n",
    "\n",
    "from tqdm import tqdm\n",
    "from polara.preprocessing.dataframes import matrix_from_observations\n",
    "\n",
    "from lfm import build_lfm_model, encode_virus_features\n",
    "from evaluation import topn_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Fn7RcpOzZLA"
   },
   "source": [
    "# Setting up Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hlyim7sHzZLW"
   },
   "source": [
    "For your convenience, we've setup Kaggle leaderboard for this home assignment. This will help you to immediately get an understanding of whether you're on the right way. If you submission gets you 0 score, something is wrong with your implementation.\n",
    "\n",
    "To submit your solutions automatically, you need to \n",
    "1. Register at the competition page. Use [this link](https://www.kaggle.com/t/4c8fd62231ce4308806b642ac6002c07) for registering.\n",
    "2. Setup Kaggle API client via `pip install kaggle` into your environment.\n",
    "3. Store your Kaggle API credentials locally. See [this instruction](https://github.com/Kaggle/kaggle-api#api-credentials) for details.\n",
    "\n",
    "Before uploading the solution, convert it into the proper format and save it locally, using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "cIyryBTZzZLY"
   },
   "outputs": [],
   "source": [
    "def save_submission(recs, test_user_index, item_index, name='kaggle_submission.csv'):\n",
    "    \"\"\"\n",
    "    Saves the recommendations for test users in a CSV file in a proper format,\n",
    "    ready for upload as a Kaggle submission.\n",
    "    It also converts internal indices into their original external representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    recs : numpy.ndarray\n",
    "        An array of shape (num_test_users, num_recommendations) containing the\n",
    "        indices of the recommended items.\n",
    "    test_user_index : pd.Index\n",
    "        Pandas Index containing the external test user indices.\n",
    "    item_index : pd.Index\n",
    "        Pandas Index containing the index mapping for the item indices.\n",
    "    name : str, optional\n",
    "        Name of the output file. Defaults to 'kaggle_submission.csv'.\n",
    "\n",
    "    Returns:\n",
    "        None \n",
    "    \"\"\"\n",
    "    submission = pd.Series(\n",
    "        data = list(item_index.take(recs).values),\n",
    "        index = test_user_index,\n",
    "        name = 'compound_id'\n",
    "    ).apply(lambda x: ' '.join([str(i) for i in x])).reset_index()\n",
    "    submission.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9um_4yVzZMI"
   },
   "source": [
    "After the solution is saved, you can upload it using the command in the following format:\n",
    "\n",
    "```\n",
    "!kaggle competitions submit -c {competition_name} -f {submission_file} -m 'my submision name'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TpFUxQkzZMI"
   },
   "source": [
    "The competition name is provided below. Do not change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "nYdDTHJhzZMJ"
   },
   "outputs": [],
   "source": [
    "competition_name = 'anti-viral-drug-discovery-skoltech-recsys-course'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MusbVnmIzZMK"
   },
   "source": [
    "**NOTE #1:** Kaggle only allows up to 20 submissions per day. Try to use the submissions budget wisely.  \n",
    "\n",
    "**NOTE #2:** If you find it more convenient, you can still submit solutions manually without using the code provided above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRvUAeAezZMK"
   },
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buP-HHWOzZML"
   },
   "source": [
    "You will work with two sources of data:  \n",
    "- activation data (`virus_chem_activation.csv`)\n",
    "  - describes if there is a positive (+1) or negative (-1) response from a virus to a chemical compound\n",
    "    - positive activation means that the compound is likely to be effective against the virus\n",
    "    - negative activation means the the virus is chemically resistant to the compound\n",
    "- virus family data (`virus_features.csv`)\n",
    "  - describes which viral family class each virus belongs to\n",
    "\n",
    "\n",
    "Your target viruses are listed below by their `virus_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "j_KDwmGwzZMM"
   },
   "outputs": [],
   "source": [
    "cold_start_viruses = pd.Index([599, 757, 1076, 1200, 1421, 1970, 2170, 2724], name='virus_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o59IH79bzZMM"
   },
   "source": [
    "\n",
    "Your global task:\n",
    " - for each target virus, identify top-5 compounds that might have positive activation on them.\n",
    " \n",
    " Note that unlike typical scenario, in this case, the target viruses must maximally dislike the recommendations. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZvLXUp0zZMN"
   },
   "source": [
    "## Data for binary classification? (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7VHYY1HzZMN"
   },
   "source": [
    "Would it be possible to simply formulate the task in terms of a binary classification with  `[+1.0, -1.0]` labels ? Describe the pros and cons of such an approach? Is it applicable in the current task?\n",
    "\n",
    "**Hint:** How many types of \"feedback\" do we actually have? Is it just two?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cUJB0XPzZMO"
   },
   "source": [
    "#your answer here  \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w09h15iYzZMO"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "_f0tIjHTzZMP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound_id</th>\n",
       "      <th>virus_id</th>\n",
       "      <th>activated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40472</th>\n",
       "      <td>516059</td>\n",
       "      <td>3174</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40473</th>\n",
       "      <td>516063</td>\n",
       "      <td>3174</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40474</th>\n",
       "      <td>573139</td>\n",
       "      <td>3174</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40475</th>\n",
       "      <td>615133</td>\n",
       "      <td>3174</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40476</th>\n",
       "      <td>1303637</td>\n",
       "      <td>3174</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       compound_id  virus_id  activated\n",
       "40472       516059      3174       -1.0\n",
       "40473       516063      3174        1.0\n",
       "40474       573139      3174       -1.0\n",
       "40475       615133      3174       -1.0\n",
       "40476      1303637      3174        1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('virus_chem_activation.csv')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "HYlddl0BzZMP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound_id</th>\n",
       "      <th>virus_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>4344</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3791</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           compound_id  virus_id\n",
       "activated                       \n",
       "-1.0              4344        88\n",
       " 1.0              3791       100"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('activated').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "p_QM4FdyzZMQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>virus_id</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>480</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>483</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>502</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   virus_id  family\n",
       "0       103    1814\n",
       "1       480    1882\n",
       "2       481    1882\n",
       "3       483    1882\n",
       "4       502    1884"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virus_families = pd.read_csv('virus_features.csv')\n",
    "virus_families.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUM-wvuvzZMQ"
   },
   "source": [
    "## Check data consistency (total 5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOH2re7KzZMQ"
   },
   "source": [
    "### cold start setting  (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXhJ3jlhzZMR"
   },
   "source": [
    "Recall that scientific labs were not able to identify compounds that would be effective against the target viruses.  \n",
    "\n",
    "Veryfy that there is `no positive activation` data for these viruses in the provided dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "KDDvvneDzZMR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here:\n",
    "data.set_index('virus_id').loc[cold_start_viruses].activated.sum() + len(data.set_index('virus_id').loc[cold_start_viruses].activated.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBN_HVHQzZMS"
   },
   "source": [
    "### lack of features (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGJpe60FzZMS"
   },
   "source": [
    "Recall that despite the joint attempts of many scientits, only general families of the new viruses were identified. These families may not be necessarily associated with compounds that give positive activations against the viruses of the family. \n",
    "\n",
    "Verify this by calculating the proportion of families of target viruses among all families associated with positive activation against at least one compound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "usXGNPLdzZMT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18181818181818182"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "num_active_families = 0\n",
    "for fam in virus_families.family.unique():\n",
    "    activated = False\n",
    "    for virus in virus_families.groupby('family').get_group(fam).values[:, 0]:\n",
    "        if virus in data.virus_id.unique():\n",
    "            if 1.0 in data[['virus_id', 'activated']].groupby('virus_id').get_group(virus).values[:, 1]:\n",
    "                activated = True\n",
    "    if activated:\n",
    "        num_active_families += 1\n",
    "virus_families.set_index('virus_id').loc[cold_start_viruses].family.nunique() / num_active_families"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6ebPeE0zZMT"
   },
   "source": [
    "## Feature pre-processing (total 5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiJ4nItKzZMU"
   },
   "source": [
    "- Your task now is to design a proper hybrid recommender for the cold start setting considering all the features that you were provided with. The solution will be based on the [`LightFM`](https://github.com/lyst/lightfm/) approach.\n",
    "\n",
    "- As you have already verified, the `virus family` feature is not sufficient for the task, as it is not fully covered by the positive activation data. Some additional information must be used.\n",
    "\n",
    "Before proceeding, try to pause here and think what esle can be used as an additional feature?  \n",
    "- **Hint #1**: Recall NSVD or SVD++ models. What were the design matrices composed of in their case?\n",
    "- **Hint #2**: How many types of interactions are there in the activation data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU2FhTiOzZMU"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkA6YWt4zZMV"
   },
   "source": [
    "### resistance feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1T7G-fjzZMV"
   },
   "source": [
    "Let's denote the ability of viruses to remain intact under action of chemical comounds as `resistance`.\n",
    "\n",
    "This type of information corresponds to the `activated == -1.0` values in the provided activation dataset. You have probably already guessed that this is exactly the type of feature that you can additionally use in construction of a hybrid recommender.\n",
    "\n",
    "- Prepare the `resistance feature` dataset by taking out the corresponding entries from the activation dataset.\n",
    "- Store the data in the `resistance` dataframe.\n",
    "- Put the positive activation data into a separate `train_data` dataframe. This dataframe will be used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "marhjVznzZMW"
   },
   "source": [
    "#### extracting additional feature data (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound_id</th>\n",
       "      <th>virus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24630</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>451356</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525524</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>525528</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>541277</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40446</th>\n",
       "      <td>1349220</td>\n",
       "      <td>2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40471</th>\n",
       "      <td>468192</td>\n",
       "      <td>3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40472</th>\n",
       "      <td>516059</td>\n",
       "      <td>3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40474</th>\n",
       "      <td>573139</td>\n",
       "      <td>3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40475</th>\n",
       "      <td>615133</td>\n",
       "      <td>3174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20372 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       compound_id  virus_id\n",
       "0            24630       103\n",
       "1           451356       103\n",
       "2           525524       103\n",
       "3           525528       103\n",
       "4           541277       103\n",
       "...            ...       ...\n",
       "40446      1349220      2989\n",
       "40471       468192      3174\n",
       "40472       516059      3174\n",
       "40474       573139      3174\n",
       "40475       615133      3174\n",
       "\n",
       "[20372 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('activated').get_group(-1.0)[['compound_id', 'virus_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "uWZiRsXjzZMa"
   },
   "outputs": [],
   "source": [
    "# your code here:\n",
    "resistance =  data.groupby('activated').get_group(-1.0)[['compound_id', 'virus_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "UlKMuO4WzZMb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compound_id    4344\n",
       "virus_id         88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resistance.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPmlWkYEzZMb"
   },
   "source": [
    "#### extracting training data (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "nHC_WY6FzZMc"
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "train_data = data.groupby('activated').get_group(1.0)[['virus_id', 'compound_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virus_id        100\n",
       "compound_id    3791\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYKE60FJzZMc"
   },
   "source": [
    "It's a good idea to immediately transform the training data into a convenient sparse format and to build the corresponding index of viruses and compounds. You did it several times throughout the course already. Below is an example of how it can be achieved with the `matrix_from_observations` function form `polara`. No additional code is required here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "2sao2ew8zZMc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x3791 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20105 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix, virus_index, compound_index = matrix_from_observations(\n",
    "    train_data, userid='virus_id', itemid='compound_id'\n",
    ")\n",
    "train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPmPpPdLzZMd"
   },
   "source": [
    "### transforming features into proper format (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JD4VTdr7zZMd"
   },
   "source": [
    "According to the LightFM documentation, features must be represented in the format of `sparse matrices` with\n",
    "- rows corresponding to an entity the feature describes and\n",
    "- columns corresponding to the feature values.\n",
    "\n",
    "You are provided with the convenience function named `encode_virus_features` which takes as an input:\n",
    "- a virus feature dataframe,\n",
    "- an array of viruses (in the form of `pandas Index`) which features are to be encoded\n",
    "- the name of the columns corresponding to the selected feature type\n",
    "\n",
    "and returns\n",
    "- a sparse binary feature matrix (one-hot encoding of features) and\n",
    "- the corresponding feature index that maps columns of the matrix back into the original features of viruses from the training.\n",
    "\n",
    "The feature index will be later used for preprocessing the features of the target viruses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kv991j1zZMe"
   },
   "source": [
    "#### resistance into sparse format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "pRkBbLivzZMe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x4313 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19744 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here:\n",
    "virus_strength_feature_matrix, virus_strength_feature_idx = encode_virus_features(\n",
    "     data=resistance, virus_index=virus_index, feature_field='compound_id'\n",
    ")\n",
    "virus_strength_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "-nKY86v-zZMf"
   },
   "outputs": [],
   "source": [
    "assert virus_strength_feature_matrix.shape[0] == len(virus_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH08xl85zZMg"
   },
   "source": [
    "#### virus family into sparse format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxdGVfFDzZMg"
   },
   "source": [
    "Do the same transformation for the `virus family` feature below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "7xWb_MY_zZMh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x44 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 100 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here:\n",
    "virus_family_feature_matrix, virus_family_feature_idx = encode_virus_features(\n",
    "    data=virus_families, virus_index=virus_index, feature_field='family'\n",
    ")\n",
    "virus_family_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "5mImOF8vzZMh"
   },
   "outputs": [],
   "source": [
    "assert virus_family_feature_matrix.shape[0] == len(virus_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9qWXe-wzZMi"
   },
   "source": [
    "## Transform target viruses' features into sparse format (total 2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykw-KxZTzZMi"
   },
   "source": [
    "You also need to perform the corresponding transformation of features for the target viruses that are not part of the train by construction.\n",
    "\n",
    "- Recall that not all target viruses have their `family` feature represented in the train data. The same holds for the `resistance` feature as well.\n",
    "- The `encode_virus_features` takes care of that by filtering out the non-consistent features that cannot be a part of the training.\n",
    "- To make it work you just need to provide the proper index of the features obtained at the earlier steps of the feature transformation:\n",
    "  - the index must be provided via an optional argument `feature_index` (must be of `pandas Index` type),\n",
    "  - mind that all features that are not covered by the provided feature index must be discarded (controlled by the `drop_invalid` argument, `True` by default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VnNX-FGzZMi"
   },
   "source": [
    "### resistance (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "9H6qMHjZzZMj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x4313 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 77 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in the missing parts of the code:\n",
    "virus_cold_start_strength_feature_matrix, virus_cold_start_strength_feature_idx = encode_virus_features(\n",
    "    data = resistance,\n",
    "    virus_index = cold_start_viruses,\n",
    "    feature_field = 'compound_id',\n",
    "    feature_index = virus_strength_feature_idx, # provide the proper feature index\n",
    "    drop_invalid = True  # filter out features inconsistent with train data\n",
    ")\n",
    "virus_cold_start_strength_feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bU1Wtqu0zZMj"
   },
   "source": [
    "### family (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "91mfrSjszZMk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x44 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in the missing parts of the code:\n",
    "virus_cold_start_family_feature_matrix, virus_cold_start_family_feature_idx = encode_virus_features(\n",
    "    data = virus_families,\n",
    "    virus_index = cold_start_viruses,\n",
    "    feature_field = 'family',\n",
    "    feature_index = virus_family_feature_idx, # provide the proper feature index\n",
    "    drop_invalid = True  # filter out features inconsistent with train data\n",
    ")\n",
    "virus_cold_start_family_feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kqXJxeizZMk"
   },
   "source": [
    "# Building the hybrid recommender model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEdjy4vxzZMk"
   },
   "source": [
    "Your task is to gradually improve the model following the instructions provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xZL1RsBzZMl"
   },
   "source": [
    "## Initial setup for LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbDi9YFvzZMl"
   },
   "source": [
    "### data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "YzpwdIZEzZMm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': 'virus_id',\n",
       " 'items': 'compound_id',\n",
       " 'n_users': 100,\n",
       " 'n_items': 3791,\n",
       " 'item_features': None}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description = dict(\n",
    "    users = 'virus_id',\n",
    "    items = 'compound_id',\n",
    "    n_users = len(virus_index),\n",
    "    n_items = len(compound_index),\n",
    "    # user_features = ... skip for now, will be defined later\n",
    "    item_features = None # compound features are not present in the dataset\n",
    ")\n",
    "data_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OWYcAtKzZMm"
   },
   "source": [
    "You will use a separate data description dictionary for generating predictions. This dictionary will provide the necessary information about the target viruses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "65bcY8pYzZMm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': 'virus_id',\n",
       " 'items': 'compound_id',\n",
       " 'n_cold_users': 8,\n",
       " 'n_items': 3791,\n",
       " 'item_features': None}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description_cold_start = dict(\n",
    "    users = 'virus_id',\n",
    "    items = 'compound_id',\n",
    "    n_cold_users = len(cold_start_viruses),\n",
    "    n_items = len(compound_index),\n",
    "    # user_features = ... skip for now, will be defined later\n",
    "    item_features = None # compound features are not present in the dataset\n",
    ")\n",
    "data_description_cold_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQS7NYXnzZMn"
   },
   "source": [
    "### hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "IDCLdrwMzZMo"
   },
   "outputs": [],
   "source": [
    "lfm_config = dict(\n",
    "    no_components = 60,\n",
    "    loss = 'warp',\n",
    "    max_sampled = 1,\n",
    "    max_epochs = 60,\n",
    "    learning_schedule = 'adagrad',\n",
    "    user_alpha = 1e-3,\n",
    "    item_alpha = 1e-3,\n",
    "    random_state = 7032023\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qz-RJQy2zZMp"
   },
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "v_poRzTUzZMr"
   },
   "outputs": [],
   "source": [
    "topn = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDn_xSwOzZMs"
   },
   "source": [
    "## The simplest case - using the \"family\" feature (total 10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AKXdZaqzZMt"
   },
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "jZnrSXt_zZNW"
   },
   "outputs": [],
   "source": [
    "data_description['user_features'] = virus_family_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "aOWw08F-zZNX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 145.46it/s]\n"
     ]
    }
   ],
   "source": [
    "lfm_model = build_lfm_model(\n",
    "    lfm_config,\n",
    "    train_matrix,\n",
    "    data_description,\n",
    "    iterator = tqdm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zvr6TazrzZNX"
   },
   "source": [
    "### generating predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRIn8zTHzZNY"
   },
   "source": [
    "#### Implement scoring function (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "KQFnuv2pzZNY"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def lightfm_scoring_base(model, data, data_description):\n",
    "    \"\"\"\n",
    "    A standard scoring function adopted for use with LightFM in the user cold-start settings.\n",
    "    \"\"\"\n",
    "    dtype = 'i4'\n",
    "    \n",
    "    all_items = np.arange(data_description['n_items'], dtype=dtype)\n",
    "    test_users = np.arange(data_description['n_cold_users'], dtype=dtype)\n",
    "    user_index, item_index = np.meshgrid(test_users, all_items, copy=False)\n",
    "    lfm_scores = model.predict(\n",
    "        user_ids = user_index.ravel(),\n",
    "        item_ids = item_index.ravel(),\n",
    "        item_features = None,\n",
    "        user_features = data_description['user_features']\n",
    "    )\n",
    "    scores = lfm_scores.reshape(len(test_users), len(all_items), order='F')    \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kopPoE36zZNZ"
   },
   "source": [
    "Use `data_description_cold_start` dictionary to initialize the required variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "NHRDCnm-zZNa"
   },
   "outputs": [],
   "source": [
    "data_description_cold_start['user_features'] = virus_cold_start_family_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "XZmceF46zZNb"
   },
   "outputs": [],
   "source": [
    "lfm_scores = lightfm_scoring_base(lfm_model, None, data_description_cold_start)\n",
    "lfm_recs = topn_recommendations(lfm_scores, topn=topn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMmq2_nSzZNc"
   },
   "source": [
    "#### Evaluate the result using Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Zzn97C2tzZNd"
   },
   "outputs": [],
   "source": [
    "# kaggle_submission_name = 'base_model.csv'\n",
    "\n",
    "# save_submission(\n",
    "#     lfm_recs, cold_start_viruses, compound_index, name=kaggle_submission_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "sz3_LYFvzZNe"
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c {competition_name} -f {kaggle_submission_name} -m 'base model v.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnwwO4PDzZNf"
   },
   "source": [
    "Please also report the obtained score on the Kaggle leaderboard here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is 0.06896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnU2cSrLzZNf"
   },
   "source": [
    "### handling biases (total 13 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdRWSKgLzZNf"
   },
   "source": [
    "It is perhaps reasonable to assume that most popular and effective compounds are known to scientists and most likely have been tried out in the first place with the new viruses. As there's still no positive activation data, it means that the predictive model must avoid favoring popular compounds in recommendations.\n",
    "\n",
    "Recall that, in the `LightFM` model, the major popularity biases are captured in the linear bias terms. Also note that:\n",
    "- when measured across different items, the variance of the bias prediction term $\\operatorname{Var}_y\\left[b^\\top y\\right]$ can be higher than the variance of the factorization term $\\operatorname{Var}_y\\left[x^\\top PQ^\\top y\\right]$\n",
    "  - if this is the case, the difference in predicted scores related to the factorization term may become negligible and won't affect ranking of the items;\n",
    "  - in other words, the recommendations of your model may promote items with the highest bias values and provide little to no personalization.\n",
    "- Unfortunately, `LightFM` neither lets you to disable biases nor does it provide a separate regularisation coefficient for linear biases (so that their influence could be decreased).\n",
    "- Hence, you will use a simple heuristic - just set biases to 0 when generating prediction scores\n",
    "\n",
    "\n",
    "**The task**:\n",
    "- implement scoring function that allows disabling linear bias terms for items. (10 pts)\n",
    "  - implement a new variant of the scoring function that takes an additional **boolean** argument `item_bias` as input\n",
    "    - if `item_bias` is `False`, the function must temporarily set the corresponding bias terms to 0 when computng prediction scores\n",
    "  - you can access `LightFM`'s biases array via `model.item_biases` variable (see [documentation](https://making.lyst.com/lightfm/docs/lightfm.html))\n",
    "    - make sure to store the current values of biases in a temporary array using the `numpy`'s `.copy()` function\n",
    "    - set all item bias weights to zero via an inplace operation `*= 0`\n",
    "  - don't forget to restore biases once the the prediction scores are generated;:\n",
    "    - use the `model.item_biases[:] = ...` syntax to make sure you're not creating a new varibale\n",
    "\n",
    "You are only required to handle biases related to compounds.  \n",
    "- Explain, why the linear bias term related to viruses do not play any role in the task? (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jWTQ-2__zZNh"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def lightfm_scoring(model, data, data_description, item_bias=True):\n",
    "    dtype = 'i4'\n",
    "    \n",
    "    all_items = np.arange(data_description['n_items'], dtype=dtype)\n",
    "    test_users = np.arange(data_description['n_cold_users'], dtype=dtype)\n",
    "    user_index, item_index = np.meshgrid(test_users, all_items, copy=False)\n",
    "    \n",
    "    \n",
    "    biases = model.item_biases.copy()\n",
    "    if not item_bias:\n",
    "        model.item_biases[:] = np.zeros_like(model.item_biases)\n",
    "        \n",
    "    lfm_scores = model.predict(\n",
    "            user_ids = user_index.ravel(),\n",
    "            item_ids = item_index.ravel(),\n",
    "            item_features = None,\n",
    "            user_features = data_description['user_features']\n",
    "        )\n",
    "    \n",
    "    model.item_biases[:] = biases\n",
    "        \n",
    "    scores = lfm_scores.reshape(len(test_users), len(all_items), order='F') \n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHfSTmUlzZNi"
   },
   "source": [
    "#### regenerating scores with disabled biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "7T818a8izZNi"
   },
   "outputs": [],
   "source": [
    "lfm_scores = lightfm_scoring(lfm_model, None, data_description_cold_start, item_bias=False)\n",
    "lfm_recs = topn_recommendations(lfm_scores, topn=topn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-gijt8ozZNj"
   },
   "source": [
    "#### evaluate the result using Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "Eb_uToLFzZNj"
   },
   "outputs": [],
   "source": [
    "# kaggle_submission_name = 'debiased_model.csv'\n",
    "\n",
    "# save_submission(\n",
    "#     lfm_recs, cold_start_viruses, compound_index, name=kaggle_submission_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "WLiDHg27zZNk"
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c {competition_name} -f {kaggle_submission_name} -m 'debiased model v.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXlmW2RGzZNk"
   },
   "source": [
    "Please also report the obtained score on the Kaggle leaderboard here.\n",
    "\n",
    "Was the hypothesis about the influence of bias terms confirmed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score increased to 0.10344."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AuiDrbmzZNk"
   },
   "source": [
    "## Improved model (total 10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYTqVqzJzZNl"
   },
   "source": [
    "Note that so far you have not implemented a truly hybrid model:\n",
    "- By default, `LightFM` utilizes information about user and item `id`'s only when no feature matrices are provided (unless you use the `lightfm.data.Dataset` class, see [documentation](https://making.lyst.com/lightfm/docs/lightfm.html)).\n",
    "- In the current setup, with explicitly provided `virus family` feature matrix, `LightFM` does not automatically extend the feature space with the `id`'s of the viruses.\n",
    "\n",
    "Hence, the collaborative information is not yet utilized in the best possible way:\n",
    "- a virus is simply represented as a bag of features.\n",
    "- Recall that several viruses can belong to the same family.\n",
    "  - Hence, the **expressiveness of the current virus representation is limited**.\n",
    "\n",
    "The task: (5 pts)\n",
    "- In order to resolve this issue, you need to manually extend representation of viruses by adding one-hot encoding of their `id`'s into the feature matrix.\n",
    "- You can use functions called `eye` and `hstack` from `scipy.sparse`.\n",
    "  - These functions are already imported in this notebook and accessible via the names `speye` and `sp_hstack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': 'virus_id',\n",
       " 'items': 'compound_id',\n",
       " 'n_users': 100,\n",
       " 'n_items': 3791,\n",
       " 'item_features': None,\n",
       " 'user_features': <100x44 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 100 stored elements in Compressed Sparse Row format>}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "gYNtm63azZNl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': 'virus_id',\n",
       " 'items': 'compound_id',\n",
       " 'n_users': 100,\n",
       " 'n_items': 3791,\n",
       " 'item_features': None,\n",
       " 'user_features': <100x144 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 200 stored elements in COOrdinate format>}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "data_description['user_features'] = sp_hstack(\n",
    "    [speye(data_description['user_features'].shape[0]), \n",
    "     virus_family_feature_matrix]\n",
    ")\n",
    "data_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_hJ6atTzZNo"
   },
   "source": [
    "### retrain the extended model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "zansDC1tzZNo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 145.36it/s]\n"
     ]
    }
   ],
   "source": [
    "lfm_model = build_lfm_model(\n",
    "    lfm_config,\n",
    "    train_matrix,\n",
    "    data_description,\n",
    "    iterator = tqdm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID-BejMSzZNp"
   },
   "source": [
    "### generate recommendations (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wz5E8PCzZNp"
   },
   "source": [
    "You also need to update the representation for the target viruses.\n",
    "\n",
    "- Note that there is no `id` feature for the target viruses in the model because they are not part of the training data.\n",
    "- Hence, you simply need to add an empty block of the proper shape to conform with the extended feature space.\n",
    "    - Use `csr_matrix` constructor to generate an empty matrix of conforming size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': 'virus_id',\n",
       " 'items': 'compound_id',\n",
       " 'n_cold_users': 8,\n",
       " 'n_items': 3791,\n",
       " 'item_features': None,\n",
       " 'user_features': <8x44 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 4 stored elements in Compressed Sparse Row format>}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description_cold_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': 'virus_id',\n",
       " 'items': 'compound_id',\n",
       " 'n_users': 100,\n",
       " 'n_items': 3791,\n",
       " 'item_features': None,\n",
       " 'user_features': <100x144 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 200 stored elements in COOrdinate format>}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "4i_tmOa9zZNp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': 'virus_id',\n",
       " 'items': 'compound_id',\n",
       " 'n_cold_users': 8,\n",
       " 'n_items': 3791,\n",
       " 'item_features': None,\n",
       " 'user_features': <8x144 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 4 stored elements in Compressed Sparse Row format>}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "data_description_cold_start['user_features'] = sp_hstack(\n",
    "    [csr_matrix((data_description_cold_start['n_cold_users'], data_description['n_users'])),\n",
    "        virus_cold_start_family_feature_matrix]\n",
    ")\n",
    "data_description_cold_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "z2ZCjaYUzZNr"
   },
   "outputs": [],
   "source": [
    "lfm_scores = lightfm_scoring(lfm_model, None, data_description_cold_start, item_bias=False)\n",
    "lfm_recs = topn_recommendations(lfm_scores, topn=topn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM7qmAl9zZNs"
   },
   "source": [
    "### evaluate the result using Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "Y40FIIpVzZNs"
   },
   "outputs": [],
   "source": [
    "# kaggle_submission_name = 'improved_model.csv'\n",
    "\n",
    "# save_submission(\n",
    "#     lfm_recs, cold_start_viruses, compound_index, name=kaggle_submission_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "qlpJDZWezZNt"
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c {competition_name} -f {kaggle_submission_name} -m 'improved model v.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPrODDsnzZNt"
   },
   "source": [
    "Please report the obtained score on the Kaggle leaderboard here.\n",
    "\n",
    "- Were you able to improve the metric?\n",
    "- How does enabling/disabling item biases affect the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If i disable biases, it has the same score as previous submission (0.13793 with item_bias = False and 0.10344 with item_bias = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vb5ApFxQzZNt"
   },
   "source": [
    "## Including the virus resistance feature (total 15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8o9FiPOVzZNu"
   },
   "source": [
    "Following the same steps as before, construct an extended representation of virus features that utilizes of three types of information:\n",
    "- collaborative\n",
    "- virus family features\n",
    "- virus resistance against compounds\n",
    "\n",
    "\n",
    "Note that each virus may have been testsed against several different compounds with negative activation result.\n",
    "- Hence, the two types of features -- `family` and `resistance` -- will have an unequal contribution into the feature representation.\n",
    "- The `resistance` feature will dominate for viruses with a lot of experimental data.\n",
    "\n",
    "Your task now is not only to extend the feature space but also to properly normalize the `resistance` feature so that its contribution becomes comparable to that of the `family` feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4Uco0ZJzZNu"
   },
   "source": [
    "### extending feature space with the normalized resistance feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VtdXMgazZNu"
   },
   "source": [
    "You need to perform two steps:\n",
    "- Implement a simple feature normalization function that will normalize each row in a feature matrix by the number of non-zero elements in this row.\n",
    "  - You can use `diags` function from `scipy.sparse` for weights. It is already imported in the notebook under the name `spdiags`.\n",
    "- Apply the function to the `resistance` feature matrix before extending the feature space. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "mQydGouSzZNv"
   },
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    '''\n",
    "    Normalize the input sparse binary feature matrix for every row.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_matrix : scipy.sparse.csr_matrix\n",
    "        The input feature matrix, where each row is a binary feature vector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scipy.sparse.csr_matrix\n",
    "        The normalized feature matrix, where each row is a probability distribution \n",
    "        over the features.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    For a feature matrix (take A as a sparse matrix) A= [[1, 0, 1], [0, 0, 1], [1, 1, 1]], \n",
    "    the normalized feature matrix is [[0.5, 0, 0.5], [0, 0, 1], [0.333, 0.333, 0.333]].\n",
    "\n",
    "    Take into account that this function takes and returns sparse matrices. \n",
    "    Dense matrices are used here for the sake of example.\n",
    "    >>> A = np.array([[1, 0, 1], [0, 0, 1], [1, 1, 1]])\n",
    "    >>> normalize_features(spdiags(A).tocsr())\n",
    "    array([[0.5  , 0.   , 0.5  ],\n",
    "           [0.   , 0.   , 1.   ],\n",
    "           [0.333, 0.333, 0.333]])\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The normalization is performed by dividing each row by the sum of its non-zero \n",
    "    elements. If a row has all zeros, it is left unchanged.\n",
    "    '''\n",
    "    # your code here\n",
    "    sums = np.array(feature_matrix.sum(axis=1))\n",
    "    sums[sums == 0] = 1\n",
    "    return feature_matrix / sums\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEqcDsI3zZNz"
   },
   "source": [
    "Use the `normalize_features` function that you implemented to get the extended feature representation that includes all three type of information: (10 pts)\n",
    "- colaborative\n",
    "- feature family\n",
    "- resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "mbzLkHRTzZNz"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "data_description['user_features'] = sp_hstack(\n",
    "    [speye(data_description['user_features'].shape[0]), \n",
    "     virus_family_feature_matrix,\n",
    "     normalize_features(virus_strength_feature_matrix)]\n",
    ")\n",
    "\n",
    "data_description_cold_start['user_features'] = sp_hstack(\n",
    "    [csr_matrix((data_description_cold_start['n_cold_users'], data_description['n_users'])),\n",
    "        virus_cold_start_family_feature_matrix,\n",
    "        normalize_features(virus_cold_start_strength_feature_matrix)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBnREqjMzZN0"
   },
   "source": [
    "### generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "QAcBVmbIzZN0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:12<00:00,  4.95it/s]\n"
     ]
    }
   ],
   "source": [
    "lfm_model = build_lfm_model(\n",
    "    lfm_config,\n",
    "    train_matrix,\n",
    "    data_description,\n",
    "    iterator = tqdm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "g_PzX0yRzZN1"
   },
   "outputs": [],
   "source": [
    "lfm_scores = lightfm_scoring(lfm_model, None, data_description_cold_start, item_bias=True)\n",
    "lfm_recs = topn_recommendations(lfm_scores, topn=topn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fbd0JH_5zZN1"
   },
   "source": [
    "### evaluate the result using Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "1JhBUkOZzZN1"
   },
   "outputs": [],
   "source": [
    "# kaggle_submission_name = 'all_features_model.csv'\n",
    "\n",
    "# save_submission(\n",
    "#     lfm_recs, cold_start_viruses, compound_index, name=kaggle_submission_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "i9frL9YxzZN2"
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c {competition_name} -f {kaggle_submission_name} -m 'all features model v.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bERORdf4zZN3"
   },
   "source": [
    "Please report the obtained score on the Kaggle leaderboard here.\n",
    "\n",
    "- Were you able to improve the metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it has improved. The score now is 0.17241"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLPX2fl6zZN3"
   },
   "source": [
    "Before proceeding, try to explain why you obtained this result after modifying the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBdr0HmDzZN4"
   },
   "source": [
    "## Relative feature weighting (total 10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z61q7DuBzZN4"
   },
   "source": [
    "Note that once all three types of features are added, their relative contribution uniformly decreases.\n",
    "- In the beginning, you had collaborative and `family` features, so their relative contribution was one half.\n",
    "- With extended representation the contribution is one third for each type.\n",
    "\n",
    "Hypothesis:\n",
    "- Reducing the relative contribution of collaborative part is likely to be the cause of the quality drop.\n",
    "\n",
    "The task:\n",
    "- Implement additional reweighting so that the contribution of collaborative part is one half again.\n",
    "- The distribution of relative contribution weights between the `family` and the `resistance` feature must be controlled via an additional scalar hyper-parameter $\\alpha \\in [0, 1]$, i.e.,\n",
    "  - all the `family` features must be globally multiplied by $\\alpha$,\n",
    "  - all the `resistance` features must be globally multiplied by $1-\\alpha$.\n",
    "    - That way, the scenario with only collaborative and `family` features is covered by setting $\\alpha=1$.\n",
    "    - Likewise, excluding `family` feature will correspond to $\\alpha=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "KL717-0DzZN4"
   },
   "outputs": [],
   "source": [
    "family_feature_weight = 0.45 # the alpha hyper-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEARd3GtzZPV"
   },
   "source": [
    "Define the reweightend feature space using the `family_feature_weight` value: (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "93O0k288zZPW"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "data_description['user_features'] = sp_hstack(\n",
    "    [speye(data_description['user_features'].shape[0]), \n",
    "     family_feature_weight * virus_family_feature_matrix,\n",
    "     (1.0 - family_feature_weight) * normalize_features(virus_strength_feature_matrix)]\n",
    ")\n",
    "\n",
    "data_description_cold_start['user_features'] = sp_hstack(\n",
    "    [csr_matrix((data_description_cold_start['n_cold_users'], data_description['n_users'])),\n",
    "        family_feature_weight * virus_cold_start_family_feature_matrix,\n",
    "        (1.0 - family_feature_weight) * normalize_features(virus_cold_start_strength_feature_matrix)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru8g3FZ6zZPW"
   },
   "source": [
    "### generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "cQD382m1zZPX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:12<00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "lfm_model = build_lfm_model(\n",
    "    lfm_config,\n",
    "    train_matrix,\n",
    "    data_description,\n",
    "    iterator = tqdm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "mi6qRxR6zZPX"
   },
   "outputs": [],
   "source": [
    "lfm_scores = lightfm_scoring(lfm_model, None, data_description_cold_start, item_bias=False)\n",
    "lfm_recs = topn_recommendations(lfm_scores, topn=topn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ybsEtt6zZPY"
   },
   "source": [
    "### evaluate the result using Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "qp35CSEqzZPY"
   },
   "outputs": [],
   "source": [
    "kaggle_submission_name = 'reweighted_features_model.csv'\n",
    "\n",
    "save_submission(\n",
    "    lfm_recs, cold_start_viruses, compound_index, name=kaggle_submission_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "drm-SVxwzZPZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 349/349 [00:00<00:00, 428B/s]\n",
      "Successfully submitted to Anti-viral drug discovery - Skoltech RecSys course"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c {competition_name} -f {kaggle_submission_name} -m 'reweighted features model 0.45'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gic0cBUrzZPZ"
   },
   "source": [
    "Please report the obtained score on the Kaggle leaderboard here. (5 pts)\n",
    "\n",
    "- Were you able to improve the metric?\n",
    "- Was the hypothesis confirmed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried $\\alpha=0.4$, and got 0.20689, it improved. 0.5, 0.8 gave the same result, also tried 1.0 (the same as result above in normalization) and 0.0 (got 3%, worst of all). 0.35, 0.45, 0.2 got around 10%. I'd say hypothesis doesn't work, since the score was greater than without weighting just for one value of parameter, but decreased for a bunch of other values of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "bbfd4c1a06db866dfcf3c38cf933639840ac8d4e4d1609b986b399f26427fa95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
