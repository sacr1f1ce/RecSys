{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH0OmsmhPuvk"
   },
   "source": [
    "# Federated collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfajZToNP8Ux"
   },
   "source": [
    "Your task is to implement federated collaborative filterng model for privacy-preserving personalized recommendation system.  \n",
    "In the Federated Learning paradigm, a master machine learning model is distributed to user clients, the clients use their locally stored data and model for both inference and calculating model updates. The model updates are sent back and aggregated on the server to update the master\n",
    "model then redistributed to the clients. In this paradigm, the user data never leaves the client, greatly enhancing the user’ privacy, in contrast to the traditional paradigm of collecting, storing and processing user data on a backend server beyond the user’s control. The federated updates to the model are based on a gradient approach. \n",
    "\n",
    "Specifically, the method defines three core components as below.\n",
    "1. All the item factor vectors $y_i, i = 1, ... , M$ are updated on the server and then distributed to each client $u$.\n",
    "2. The user factor vectors $x_u, u = 1, ... , N$ are updated locally on the client $u$, using the user $u$’s own data and the $y_i, i = 1, ... , M$ from the server.\n",
    "3. The updates through the gradients $\\delta y_{ui}$ are calculated for the item $i$ on each client $u$ and transmitted to the server where the gradients are aggregated to update $y_i$.\n",
    "\n",
    "The cost function optimizing across all users $u$ and the items $i$ over the confidence levels $c_{ui}$ is then given as\n",
    "\n",
    "$$J = \\sum_u \\sum_i c_{ui}(p_{ui} - x_u^T y_i)^2 + \\lambda (\\sum_u||x_u||^2 + \\sum_i ||y_i||^2),$$\n",
    "with a regularization parameter $\\lambda$,\n",
    "where \n",
    "$$p_{ui} = \\begin{cases}  \n",
    "1 & r_{ui} > 0,\\\\\n",
    "0 & r_{ui} = 0\n",
    "\\end{cases}$$\n",
    " $$c_{ui} = 1 + \\alpha r_{ui}$$\n",
    "\n",
    "User factors are updated by directly solving an equation\n",
    "\n",
    "$$ \\frac{\\partial J(x_u)}{\\partial x_u} = 0 $$\n",
    "Thus, we obtain the solution\n",
    "$$ x_u = (YC^uY^T + \\lambda I)^{-1}YC^up(u),$$\n",
    "where $ C^u \\in \\mathbb{R}^{N \\times N}$ is a diagonal matrix with $C_{ii}^u = c_{ui}$ and $p(u) \\in \\mathbb{R}^{N \\times 1}$ contains the $p_{ui}$ values for the user $u$.\n",
    "\n",
    "Item factors are updated on the master server as\n",
    "\n",
    "$$ y_i = y_i - \\gamma \\frac{\\partial J}{\\partial y_i},$$\n",
    "\n",
    "where gamma is gain parameter.\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial y_i} = -2 \\sum_u f(u,i) +2 \\lambda y_i, $$\n",
    "where \n",
    "$$ f(u,i) = \\left[ c_{ui}(p_{ui} - x_u^T y_i)\\right]x_u.$$\n",
    "\n",
    "To familiarise yourself with the method, read the paper https://arxiv.org/pdf/1901.09888.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ko6DPW-jTzP1"
   },
   "outputs": [],
   "source": [
    "#!pip install ipypb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ft1dYl4jD6hM"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7RSs4X4klJtV"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from ipypb import irange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1ODpvLJFvoWs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from polara import get_movielens_data\n",
    "from polara.evaluation.pipelines import random_grid, find_optimal_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep import transform_indices, verify_time_split\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXj3bZZJ-Loh"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf7wCfY1R4bq"
   },
   "source": [
    "For this task we will use popular MovieLens dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zLvfeClL6mJB",
    "outputId": "a6b3ddfb-a520-4637-fddc-72367e6d67c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  movieid  rating  timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_movielens_data(\n",
    "    get_genres=False, # we won't need genres\n",
    "    split_genres=False,\n",
    "    include_time=True\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHRaWsXP_GPC"
   },
   "source": [
    "# 1. Preprocess data  (5 pts)\n",
    "Do the preprocessing, including data split and index transformation. You are recommended to use functions from the seminar on evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f1g4Odt_UoJ"
   },
   "source": [
    "## Data split \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5LcFapySKc0"
   },
   "source": [
    "Split data to train/validation/test datasets, using leave-last-out scheme for holdout sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RW6LYUI3-ef8"
   },
   "outputs": [],
   "source": [
    "def leave_last_out(data, userid='userid', timeid='timestamp'):\n",
    "    data_sorted = data.sort_values('timestamp')\n",
    "    holdout = data_sorted.drop_duplicates(\n",
    "        subset=['userid'], keep='last'\n",
    "    ) # split the last item from each user's history\n",
    "    remaining = data.drop(holdout.index) # store the remaining data - will be our training\n",
    "    return remaining, holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4K-ZiiSy-emy"
   },
   "outputs": [],
   "source": [
    "training_, holdout_ = leave_last_out(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "87GBkzkFE9tP"
   },
   "outputs": [],
   "source": [
    "training_, holdout_val_ = leave_last_out(training_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gadtku-HEyNc"
   },
   "source": [
    "## Transform index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma9Q5lmLT6m8"
   },
   "source": [
    "Transform index in train dataset and reindex validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lj-gZZhbBX6S"
   },
   "outputs": [],
   "source": [
    "def transform_indices(data, users, items):\n",
    "    data_index = {}\n",
    "    for entity, field in zip(['users', 'items'], [users, items]):\n",
    "        new_index, data_index[entity] = to_numeric_id(data, field)\n",
    "        data = data.assign(**{f'{field}': new_index}) # makes a copy of dataset!\n",
    "    return data, data_index\n",
    "\n",
    "def to_numeric_id(data, field):\n",
    "    idx_data = data[field].astype(\"category\")\n",
    "    idx = idx_data.cat.codes\n",
    "    idx_map = idx_data.cat.categories.rename(field)\n",
    "    return idx, idx_map\n",
    "\n",
    "def reindex_data(data, data_index, fields=None):\n",
    "    if fields is None:\n",
    "        fields = data_index.keys()\n",
    "    if isinstance(fields, str): # handle single field provided as a string\n",
    "        fields = [fields]\n",
    "    for field in fields:\n",
    "        entity_name = data_index[field].name\n",
    "        new_index = data_index[field].get_indexer(data[entity_name])\n",
    "        data = data.assign(**{f'{entity_name}': new_index}) # makes a copy of dataset!\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Hc3CZyn_BTYx"
   },
   "outputs": [],
   "source": [
    "train_data, data_index = transform_indices(training_, 'userid', 'movieid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qMdKuyEGAr5F"
   },
   "outputs": [],
   "source": [
    "test_data = reindex_data(holdout_, data_index)\n",
    "val_data = reindex_data(holdout_val_, data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uYvEO_M6EpAF"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.query('movieid >= 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "x0ogqRXRUH9B"
   },
   "outputs": [],
   "source": [
    "# sorting data by user id for correct evaluation\n",
    "test_data = test_data.sort_values('userid') \n",
    "val_data = val_data.sort_values('userid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Wyq-iQVDDc46"
   },
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name, # user field\n",
    "    items = data_index['items'].name, # item field\n",
    "    test_users = test_data[data_index['users'].name].values,\n",
    "    holdout_items = test_data[data_index['items'].name].values,\n",
    "    val_users = val_data[data_index['users'].name].values,\n",
    "    holdout_val_items = val_data[data_index['items'].name].values,\n",
    "    n_users = train_data[data_index['users'].name].nunique(), \n",
    "    n_items = train_data[data_index['items'].name].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-rSjRwXJ-ho"
   },
   "source": [
    "# 2. Building/training a recommender model (20 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiV9vYw3lLZs"
   },
   "source": [
    "## Preparing data in matrix form\n",
    "\n",
    "Complete the function to obtain sparse matrix from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "W0fU9QH-lLZw"
   },
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, userid, itemid, feedback=None, shape=None, dtype=None):\n",
    "    '''Return sparse matrix, obtained from training data'''\n",
    "    useridx = data[userid]\n",
    "    itemidx = data[itemid]\n",
    "    values = data[feedback]\n",
    "    return csr_matrix((values, (useridx, itemidx)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xI6LhSx3lLZ1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3704 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 988129 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix = matrix_from_observations(train_data, userid='userid', itemid='movieid', feedback='rating')\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elBFTTH_lLZ2"
   },
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xGV3lDg9lLZ3"
   },
   "outputs": [],
   "source": [
    "n_users = data_description['n_users']\n",
    "n_items = data_description['n_items']\n",
    "n_factors = 50\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Me_sOssulLZ5"
   },
   "outputs": [],
   "source": [
    "# initialization of user and item factors\n",
    "random_state = np.random.RandomState(seed)\n",
    "user_factors = random_state.normal(0, 0.01, size=(n_users, n_factors))\n",
    "item_factors = random_state.normal(0, 0.01, size=(n_items, n_factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7PSlpMJlLZ9"
   },
   "source": [
    "## Server side\n",
    "\n",
    "Complete the functions to update item factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hPIxVQ9olLZ9"
   },
   "outputs": [],
   "source": [
    "def update_global_model(matrix, X, Y, regularization, gain, alpha, n_iter):\n",
    "    grad = np.zeros(Y.shape)\n",
    "    for _ in range(n_iter):\n",
    "        grad += item_factor_update(matrix, X, Y, regularization, alpha, n_iter)\n",
    "    Y -= gain * grad # update Y\n",
    "\n",
    "\n",
    "def item_factor_update(matrix, X, Y, regularization, alpha, n_iter=4):\n",
    "    '''Update item factor vectors'''\n",
    "    n_users , _ = X.shape\n",
    "    grad = 2 * regularization * Y # initialize gradient as a regularization term\n",
    "    for u in range(n_users):\n",
    "        grad += fetch_neg_client_grad(matrix, X, Y, u, alpha) # add calculated gradient for a user\n",
    "    return grad\n",
    "    \n",
    "\n",
    "def fetch_neg_client_grad(matrix, X, Y, u, alpha):\n",
    "    '''\n",
    "    Fetches for entire item collection at once\n",
    "    f(u, i) = c_ui * (p_ui - yi^T xu) xu\n",
    "    f(u, Y) = C_u *  (p_u  -   Y xu ) xu^T = - (Y xu + (Cu-1)*(Yxu - pu)) xu^T\n",
    "    '''\n",
    "    indptr = matrix.indptr # get indptr from sparse matrix\n",
    "    inds = matrix.indices # get indices from sparse matrix\n",
    "    r = matrix.data # get ratings\n",
    "    ru = np.zeros((matrix.shape[1])) \n",
    "    for i in range(indptr[u], indptr[u + 1]):\n",
    "        ru[inds[i]] = r[i]\n",
    "    Cu_ = alpha * ru\n",
    "    pu = np.zeros_like(ru)\n",
    "    pu[ru > 0] = 1\n",
    "    \n",
    "    xu = X[u] # get user's vector  \n",
    "    user_neg_grad_val = (Y @ xu - pu + Cu_ * (Y @ xu - pu)).reshape((-1, 1)) @ xu.reshape((1, -1)) \n",
    "    return 2 * user_neg_grad_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLyNcNyglLaB"
   },
   "source": [
    "## Client side\n",
    "\n",
    "Complete the functions to update user factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zLoh5lDwlLaB"
   },
   "outputs": [],
   "source": [
    "def update_local_models(matrix, X, Y, regularization, alpha):\n",
    "    n_users, n_factors = X.shape\n",
    "    YtY = Y.T @ Y + regularization * np.eye(n_factors)\n",
    "    for u in range(n_users): # to imitate locally updating on the client side\n",
    "        X[u] = user_factor_update(Y, YtY, matrix, u, alpha) # each client does independently\n",
    "\n",
    "\n",
    "def user_factor_update(Y, YtY, matrix, u, alpha):\n",
    "    '''\n",
    "    Return the solution of equation\n",
    "    Xu = (YtCuY + regularization * I)^-1 (YtCuPu)\n",
    "    '''\n",
    "    A, b = solve_linear_equation(Y, YtY, matrix, u, alpha)\n",
    "    return np.linalg.inv(A) @ b\n",
    "\n",
    "\n",
    "def solve_linear_equation(Y, YtY, matrix, u, alpha):\n",
    "    '''\n",
    "    Return A = YtCuY + regularization * I and b = YtCuPu\n",
    "    to use it later for solving the equation\n",
    "    Xu = (YtCuY + regularization * I)^-1 (YtCuPu)\n",
    "\n",
    "    Following identity might be helpful\n",
    "    YtCuY + regularization * I = YtY + regularization * I + Yt(Cu-I)Y\n",
    "    '''\n",
    "    indptr = matrix.indptr # get indptr from sparse matrix \n",
    "    inds = matrix.indices # get indices from sparse matrix\n",
    "    r = matrix.data # get ratings\n",
    "    \n",
    "    ru = np.zeros((matrix.shape[1]))\n",
    "    for i in range(indptr[u], indptr[u + 1]):\n",
    "        ru[inds[i]] = r[i]\n",
    "    Cu_ = alpha * ru\n",
    "    pu = np.zeros_like(ru)\n",
    "    pu[ru > 0] = 1\n",
    "    \n",
    "    A = YtY + (Y.T * Cu_) @ Y # accumulate YtCuY + regularization * I in A\n",
    "    b = Y.T @ pu + Y.T @ (Cu_ * pu) # accumulate YtCuPu in b\n",
    "    return A, b  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AvisiIdlLaE"
   },
   "source": [
    "## Model Training\n",
    "Complete the function to build model. Choose the hyper-parameters and store it in config. Train your model on chosen hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VmublXbnlLaH"
   },
   "outputs": [],
   "source": [
    "def build_model(model_config, trainset, trainset_description):\n",
    "    n_factors = model_config['n_factors']\n",
    "    n_epochs = model_config['n_epochs']\n",
    "    regularization = model_config['regularization']\n",
    "    gain = model_config['gain']\n",
    "    alpha = model_config['alpha']\n",
    "    n_iter = model_config['n_iter']\n",
    "    seed = model_config['seed']\n",
    "    \n",
    "    n_users = trainset_description['n_users']\n",
    "    n_items = trainset_description['n_items']\n",
    "    \n",
    "    train_matrix = trainset # get sparse matrix\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    user_factors = random_state.normal(0, 0.01, size=(n_users, n_factors)) # initialize user factors\n",
    "    item_factors = random_state.normal(0, 0.01, size=(n_items, n_factors)) # initialize user factors\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        update_global_model(train_matrix, user_factors, item_factors, regularization, gain, alpha, n_iter)\n",
    "        update_local_models(train_matrix, user_factors, item_factors, regularization, alpha)\n",
    "        # in each epoch update global model and then update local models\n",
    "            \n",
    "    return user_factors, item_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wvWK56jAlXK0"
   },
   "outputs": [],
   "source": [
    "# create config with the following hyper parameters:\n",
    "# seed, n_factors, regularization, gain, alpha, n_epochs, n_iter.\n",
    "config = {\n",
    "    'seed':0,\n",
    "    'n_factors':50,\n",
    "    'regularization':1.0,\n",
    "    'gain':0.05,\n",
    "    'alpha':1.0,\n",
    "    'n_epochs':20,\n",
    "    'n_iter':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "d4prUYPFlLaI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [06:47<00:00, 20.39s/it]\n"
     ]
    }
   ],
   "source": [
    "params = build_model(config, data_matrix, data_description) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 50)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gczc3SRolMj2"
   },
   "source": [
    "# 3. Evaluation (5 pts)\n",
    "\n",
    "Complete the functions to predict relevance scores. Using predcted scores generate top-n recommendations. Evaluate quality of recommendations and report HR@5 and MRR@5 etrics. Remember that we don't want to recommend items from the user's history. You are recommended to use functions from the previous seminars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qd6eGwAZR0-0"
   },
   "outputs": [],
   "source": [
    "topn = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1550</td>\n",
       "      <td>3</td>\n",
       "      <td>978300174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2</td>\n",
       "      <td>1900</td>\n",
       "      <td>4</td>\n",
       "      <td>978298504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>3</td>\n",
       "      <td>971</td>\n",
       "      <td>4</td>\n",
       "      <td>978294282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>4</td>\n",
       "      <td>279</td>\n",
       "      <td>2</td>\n",
       "      <td>978246585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999251</th>\n",
       "      <td>6035</td>\n",
       "      <td>2440</td>\n",
       "      <td>1</td>\n",
       "      <td>956755196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999684</th>\n",
       "      <td>6036</td>\n",
       "      <td>421</td>\n",
       "      <td>3</td>\n",
       "      <td>956801840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999731</th>\n",
       "      <td>6037</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956717204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999826</th>\n",
       "      <td>6038</td>\n",
       "      <td>1162</td>\n",
       "      <td>4</td>\n",
       "      <td>956758029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6039</td>\n",
       "      <td>1131</td>\n",
       "      <td>4</td>\n",
       "      <td>998315055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6038 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userid  movieid  rating  timestamp\n",
       "25            0       47       5  978824351\n",
       "66            1     1550       3  978300174\n",
       "232           2     1900       4  978298504\n",
       "237           3      971       4  978294282\n",
       "258           4      279       2  978246585\n",
       "...         ...      ...     ...        ...\n",
       "999251     6035     2440       1  956755196\n",
       "999684     6036      421       3  956801840\n",
       "999731     6037     1094       5  956717204\n",
       "999826     6038     1162       4  956758029\n",
       "1000042    6039     1131       4  998315055\n",
       "\n",
       "[6038 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "rrdPK2uElMj5"
   },
   "outputs": [],
   "source": [
    "# Complete model scoring function to predict relevance scores for test user-item pairs.\n",
    "def model_scoring(model_params, testset, testset_description):\n",
    "    user_factors, item_factors = model_params # get user and item factros\n",
    "    test_user_factors = user_factors[testset.userid.unique()] # get user factros for test users\n",
    "    scores = test_user_factors @ item_factors.T # get scores \n",
    "    print(scores.shape)\n",
    "    downvote_seen_items(scores, testset, data_description)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "B52qdo9dn0lk"
   },
   "outputs": [],
   "source": [
    "# Complete model recommendations function to generate top-n recommendations using predcted scores.\n",
    "def model_recom_func(model_scores, topn=5):\n",
    "    recommendations = topn_recommendations(model_scores, topn)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "JwMrJffjlMj4"
   },
   "outputs": [],
   "source": [
    "# Complete function to evaluate quality of recommendations\n",
    "def evaluate_func(model_recoms, holdout, holdout_description, topn=5):\n",
    "    hr, mrr, _ = model_evaluate(model_recoms, holdout, holdout_description, topn)\n",
    "    return hr, mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-u1a1EklMj8"
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "qePo0RPJgZuF"
   },
   "outputs": [],
   "source": [
    "userid = data_description['users']\n",
    "seen_idx_mask = train_data[userid].isin(data_description['test_users'])\n",
    "testset = train_data[seen_idx_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "jVZ024YL63At"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6038, 3704)\n",
      "HR@5 = 0.0366\n",
      "MRR@5 = 0.0173\n"
     ]
    }
   ],
   "source": [
    "test_scores = model_scoring(params, testset, data_description) # get scores\n",
    "recoms = model_recom_func(test_scores) # get recommended items\n",
    "hr, mrr = evaluate_func(recoms, test_data, data_description) # get metrics\n",
    "print(f'HR@{topn} = {hr:.4f}')\n",
    "print(f'MRR@{topn} = {mrr:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9uyF_hNlMj9"
   },
   "source": [
    "# Quick check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyVFXYPaa4Ez"
   },
   "source": [
    "Compare your model with one or two baselines and report the results. You can use code from previous seminars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5YC-DgsxVmb"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gC1tDoCRphSn"
   },
   "source": [
    "# 4. Hyper-parameter selection (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67Nl3qEePGRI"
   },
   "source": [
    "Complete the function to tune hyper-parameters of your model to provide the best quality. Train the model with the best hyper-parameters and report HR and MRR on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "h3lJ-FtzZdR7"
   },
   "outputs": [],
   "source": [
    "# you are free to change hp values\n",
    "params_dict = dict(\n",
    "    n_factors = [10, 20, 50, 100],\n",
    "    regularization = np.linspace(1, 5, 5).astype(int),\n",
    "    gain = np.logspace(-4, -2, 5),\n",
    "    alpha = np.linspace(1, 5, 5).astype(int),\n",
    "    n_epochs = [10, 15, 20, 25],\n",
    "    n_iter = np.linspace(4, 20, 5).astype(int),\n",
    "    seed = [0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "WK8C2t5auWHS"
   },
   "outputs": [],
   "source": [
    "param_grid, param_names = random_grid(params_dict, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "DiDxZxgBCfJ4"
   },
   "outputs": [],
   "source": [
    "def hp_selection(data, description, param_grid, param_names, testset, test_data):\n",
    "    ''' Return best HR value and best set of hyperparameters '''\n",
    "    data_matrix = matrix_from_observations(data, userid='userid', itemid='movieid', feedback='rating')\n",
    "    best_hr = 0\n",
    "    best_params = None\n",
    "    for parameter_model in param_grid:\n",
    "        #print(param_names, parameter_model)\n",
    "        configuration = dict(zip(param_names, parameter_model))\n",
    "        model_params = build_model(configuration, data_matrix, data_description) \n",
    "    \n",
    "        hr, mrr = evaluate_func(\n",
    "            model_recom_func(\n",
    "                model_scoring(\n",
    "                    model_params,\n",
    "                    testset,\n",
    "                    data_description\n",
    "                )\n",
    "            ), test_data,\n",
    "            data_description\n",
    "        )\n",
    "        \n",
    "        if hr > best_hr:\n",
    "            best_hr = hr\n",
    "            best_params = config\n",
    "    return best_hr, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "awIFVI1xcV--"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [38:38<00:00, 92.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6038, 3704)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [23:08<00:00, 92.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6038, 3704)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [16:50<00:00, 40.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6038, 3704)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [15:40<00:00, 94.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6038, 3704)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 22/25 [24:40<03:21, 67.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model with the best hyper-parameters and report HR and MRR on test dataset.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_hr, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mhp_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHR@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMRR@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmrr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[107], line 9\u001b[0m, in \u001b[0;36mhp_selection\u001b[0;34m(data, description, param_grid, param_names, testset, test_data)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parameter_model \u001b[38;5;129;01min\u001b[39;00m param_grid:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#print(param_names, parameter_model)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     configuration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(param_names, parameter_model))\n\u001b[0;32m----> 9\u001b[0m     model_params \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_description\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     11\u001b[0m     hr, mrr \u001b[38;5;241m=\u001b[39m evaluate_func(\n\u001b[1;32m     12\u001b[0m         model_recom_func(\n\u001b[1;32m     13\u001b[0m             model_scoring(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         data_description\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hr \u001b[38;5;241m>\u001b[39m best_hr:\n",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(model_config, trainset, trainset_description)\u001b[0m\n\u001b[1;32m     16\u001b[0m item_factors \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, size\u001b[38;5;241m=\u001b[39m(n_items, n_factors)) \u001b[38;5;66;03m# initialize user factors\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs)):\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mupdate_global_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     update_local_models(train_matrix, user_factors, item_factors, regularization, alpha)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# in each epoch update global model and then update local models\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m, in \u001b[0;36mupdate_global_model\u001b[0;34m(matrix, X, Y, regularization, gain, alpha, n_iter)\u001b[0m\n\u001b[1;32m      2\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(Y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[0;32m----> 4\u001b[0m     grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mitem_factor_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m Y \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m gain \u001b[38;5;241m*\u001b[39m grad\n",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36mitem_factor_update\u001b[0;34m(matrix, X, Y, regularization, alpha, n_iter)\u001b[0m\n\u001b[1;32m     11\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m regularization \u001b[38;5;241m*\u001b[39m Y \u001b[38;5;66;03m# initialize gradient as a regularization term\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_users):\n\u001b[0;32m---> 13\u001b[0m     grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mfetch_neg_client_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# add calculated gradient for a user\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "Cell \u001b[0;32mIn[20], line 34\u001b[0m, in \u001b[0;36mfetch_neg_client_grad\u001b[0;34m(matrix, X, Y, u, alpha)\u001b[0m\n\u001b[1;32m     31\u001b[0m pu[ru \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     33\u001b[0m xu \u001b[38;5;241m=\u001b[39m X[u] \u001b[38;5;66;03m# get user's vector  \u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m user_neg_grad_val \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCu_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m user_neg_grad_val\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model with the best hyper-parameters and report HR and MRR on test dataset.\n",
    "best_hr, best_params = hp_selection(train_data, data_description, param_grid, param_names, testset, test_data)\n",
    "print(f'HR@{topn} = {hr:.4f}')\n",
    "print(f'MRR@{topn} = {mrr:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wknmnyX8dddN"
   },
   "source": [
    "# 5. Analysis (5 pts) \n",
    "\n",
    "Examine how the loss function, $||X||$ and $||Y||$ change during the training. Complete the function to obtain the history of losses values, $||X||$ and $||Y||$ for every epoch. Use best hyper-parameters for model config. Plot the graphs and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZZqPDUtcT-Y"
   },
   "outputs": [],
   "source": [
    "def model_analysis(model_config, trainset, trainset_description):\n",
    "    ...    \n",
    "    return X_norms, Y_norms, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwVRCq9Lc8cn"
   },
   "outputs": [],
   "source": [
    "X_norms, Y_norms, losses = model_analysis(best_params, train_data, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxV6mSMyDFZG"
   },
   "outputs": [],
   "source": [
    "# Plot the graphs and discuss the results.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18cbYM8m3FR9"
   },
   "source": [
    "What is the time complexity of the federated collaborative filterng with gradient descent? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "PkfLyJ0edHNA"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16549ecea845462ba075d4e7a3b3cce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000000000\u001b[39m)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/std.py:1201\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_print_n\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminiters\u001b[49m:\n\u001b[1;32m   1202\u001b[0m     cur_t \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m   1203\u001b[0m     dt \u001b[38;5;241m=\u001b[39m cur_t \u001b[38;5;241m-\u001b[39m last_print_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(1000000000)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "interpreter": {
   "hash": "1ba68f285e1c31cfa79ad3009fb16746741280f775149535e5b791f214db1c3e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
