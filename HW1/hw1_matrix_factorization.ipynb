{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH0OmsmhPuvk"
   },
   "source": [
    "# Federated collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfajZToNP8Ux"
   },
   "source": [
    "Your task is to implement federated collaborative filterng model for privacy-preserving personalized recommendation system.  \n",
    "In the Federated Learning paradigm, a master machine learning model is distributed to user clients, the clients use their locally stored data and model for both inference and calculating model updates. The model updates are sent back and aggregated on the server to update the master\n",
    "model then redistributed to the clients. In this paradigm, the user data never leaves the client, greatly enhancing the user’ privacy, in contrast to the traditional paradigm of collecting, storing and processing user data on a backend server beyond the user’s control. The federated updates to the model are based on a gradient approach. \n",
    "\n",
    "Specifically, the method defines three core components as below.\n",
    "1. All the item factor vectors $y_i, i = 1, ... , M$ are updated on the server and then distributed to each client $u$.\n",
    "2. The user factor vectors $x_u, u = 1, ... , N$ are updated locally on the client $u$, using the user $u$’s own data and the $y_i, i = 1, ... , M$ from the server.\n",
    "3. The updates through the gradients $\\delta y_{ui}$ are calculated for the item $i$ on each client $u$ and transmitted to the server where the gradients are aggregated to update $y_i$.\n",
    "\n",
    "The cost function optimizing across all users $u$ and the items $i$ over the confidence levels $c_{ui}$ is then given as\n",
    "\n",
    "$$J = \\sum_u \\sum_i c_{ui}(p_{ui} - x_u^T y_i)^2 + \\lambda (\\sum_u||x_u||^2 + \\sum_i ||y_i||^2),$$\n",
    "with a regularization parameter $\\lambda$,\n",
    "where \n",
    "$$p_{ui} = \\begin{cases}  \n",
    "1 & r_{ui} > 0,\\\\\n",
    "0 & r_{ui} = 0\n",
    "\\end{cases}$$\n",
    " $$c_{ui} = 1 + \\alpha r_{ui}$$\n",
    "\n",
    "User factors are updated by directly solving an equation\n",
    "\n",
    "$$ \\frac{\\partial J(x_u)}{\\partial x_u} = 0 $$\n",
    "Thus, we obtain the solution\n",
    "$$ x_u = (YC^uY^T + \\lambda I)^{-1}YC^up(u),$$\n",
    "where $ C^u \\in \\mathbb{R}^{N \\times N}$ is a diagonal matrix with $C_{ii}^u = c_{ui}$ and $p(u) \\in \\mathbb{R}^{N \\times 1}$ contains the $p_{ui}$ values for the user $u$.\n",
    "\n",
    "Item factors are updated on the master server as\n",
    "\n",
    "$$ y_i = y_i - \\gamma \\frac{\\partial J}{\\partial y_i},$$\n",
    "\n",
    "where gamma is gain parameter.\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial y_i} = -2 \\sum_u f(u,i) +2 \\lambda y_i, $$\n",
    "where \n",
    "$$ f(u,i) = \\left[ c_{ui}(p_{ui} - x_u^T y_i)\\right]x_u.$$\n",
    "\n",
    "To familiarise yourself with the method, read the paper https://arxiv.org/pdf/1901.09888.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ko6DPW-jTzP1"
   },
   "outputs": [],
   "source": [
    "#!pip install ipypb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ft1dYl4jD6hM"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7RSs4X4klJtV"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from ipypb import irange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1ODpvLJFvoWs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from polara import get_movielens_data\n",
    "from polara.evaluation.pipelines import random_grid, find_optimal_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXj3bZZJ-Loh"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf7wCfY1R4bq"
   },
   "source": [
    "For this task we will use popular MovieLens dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zLvfeClL6mJB",
    "outputId": "a6b3ddfb-a520-4637-fddc-72367e6d67c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  movieid  rating  timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_movielens_data(\n",
    "    get_genres=False, # we won't need genres\n",
    "    split_genres=False,\n",
    "    include_time=True\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHRaWsXP_GPC"
   },
   "source": [
    "# 1. Preprocess data  (5 pts)\n",
    "Do the preprocessing, including data split and index transformation. You are recommended to use functions from the seminar on evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f1g4Odt_UoJ"
   },
   "source": [
    "## Data split \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5LcFapySKc0"
   },
   "source": [
    "Split data to train/validation/test datasets, using leave-last-out scheme for holdout sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RW6LYUI3-ef8"
   },
   "outputs": [],
   "source": [
    "def leave_last_out(data, userid='userid', timeid='timestamp'):\n",
    "    data_sorted = data.sort_values('timestamp')\n",
    "    holdout = data_sorted.drop_duplicates(\n",
    "        subset=['userid'], keep='last'\n",
    "    ) # split the last item from each user's history\n",
    "    remaining = data.drop(holdout.index) # store the remaining data - will be our training\n",
    "    return remaining, holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4K-ZiiSy-emy"
   },
   "outputs": [],
   "source": [
    "training_, holdout_ = leave_last_out(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "87GBkzkFE9tP"
   },
   "outputs": [],
   "source": [
    "training_, holdout_val_ = leave_last_out(training_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gadtku-HEyNc"
   },
   "source": [
    "## Transform index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma9Q5lmLT6m8"
   },
   "source": [
    "Transform index in train dataset and reindex validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lj-gZZhbBX6S"
   },
   "outputs": [],
   "source": [
    "def transform_indices(data, users, items):\n",
    "    data_index = {}\n",
    "    for entity, field in zip(['users', 'items'], [users, items]):\n",
    "        new_index, data_index[entity] = to_numeric_id(data, field)\n",
    "        data = data.assign(**{f'{field}': new_index}) # makes a copy of dataset!\n",
    "    return data, data_index\n",
    "\n",
    "def to_numeric_id(data, field):\n",
    "    idx_data = data[field].astype(\"category\")\n",
    "    idx = idx_data.cat.codes\n",
    "    idx_map = idx_data.cat.categories.rename(field)\n",
    "    return idx, idx_map\n",
    "\n",
    "def reindex_data(data, data_index, fields=None):\n",
    "    if fields is None:\n",
    "        fields = data_index.keys()\n",
    "    if isinstance(fields, str): # handle single field provided as a string\n",
    "        fields = [fields]\n",
    "    for field in fields:\n",
    "        entity_name = data_index[field].name\n",
    "        new_index = data_index[field].get_indexer(data[entity_name])\n",
    "        data = data.assign(**{f'{entity_name}': new_index}) # makes a copy of dataset!\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Hc3CZyn_BTYx"
   },
   "outputs": [],
   "source": [
    "train_data, data_index = transform_indices(training_, 'userid', 'movieid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qMdKuyEGAr5F"
   },
   "outputs": [],
   "source": [
    "test_data = reindex_data(holdout_, data_index)\n",
    "val_data = reindex_data(holdout_val_, data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uYvEO_M6EpAF"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.query('movieid >= 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "x0ogqRXRUH9B"
   },
   "outputs": [],
   "source": [
    "# sorting data by user id for correct evaluation\n",
    "test_data = test_data.sort_values('userid') \n",
    "val_data = val_data.sort_values('userid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Wyq-iQVDDc46"
   },
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name, # user field\n",
    "    items = data_index['items'].name, # item field\n",
    "    test_users = test_data[data_index['users'].name].values,\n",
    "    holdout_items = test_data[data_index['items'].name].values,\n",
    "    val_users = val_data[data_index['users'].name].values,\n",
    "    holdout_val_items = val_data[data_index['items'].name].values,\n",
    "    n_users = train_data[data_index['users'].name].nunique(), \n",
    "    n_items = train_data[data_index['items'].name].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-rSjRwXJ-ho"
   },
   "source": [
    "# 2. Building/training a recommender model (20 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiV9vYw3lLZs"
   },
   "source": [
    "## Preparing data in matrix form\n",
    "\n",
    "Complete the function to obtain sparse matrix from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "W0fU9QH-lLZw"
   },
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, userid, itemid, feedback=None, shape=None, dtype=None):\n",
    "    '''Return sparse matrix, obtained from training data'''\n",
    "    useridx = data[userid]\n",
    "    itemidx = data[itemid]\n",
    "    values = data[feedback]\n",
    "    return csr_matrix((values, (useridx, itemidx)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xI6LhSx3lLZ1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3704 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 988129 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix = matrix_from_observations(train_data, userid='userid', itemid='movieid', feedback='rating')\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elBFTTH_lLZ2"
   },
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xGV3lDg9lLZ3"
   },
   "outputs": [],
   "source": [
    "n_users = data_description['n_users']\n",
    "n_items = data_description['n_items']\n",
    "n_factors = 50\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Me_sOssulLZ5"
   },
   "outputs": [],
   "source": [
    "# initialization of user and item factors\n",
    "random_state = np.random.RandomState(seed)\n",
    "user_factors = random_state.normal(0, 0.01, size=(n_users, n_factors))\n",
    "item_factors = random_state.normal(0, 0.01, size=(n_items, n_factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7PSlpMJlLZ9"
   },
   "source": [
    "## Server side\n",
    "\n",
    "Complete the functions to update item factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPIxVQ9olLZ9"
   },
   "outputs": [],
   "source": [
    "def update_global_model(matrix, X, Y, regularization, gain, alpha, n_iter):\n",
    "    for _ in range(n_iter):\n",
    "        item_factor_update(matrix, X, Y, regularization, alpha, n_iter)\n",
    "    Y -= gain # update Y\n",
    "\n",
    "\n",
    "def item_factor_update(matrix, X, Y, regularization, alpha, n_iter=4):\n",
    "    '''Update item factor vectors'''\n",
    "    n_users , _ = X.shape\n",
    "    grad = 2 * regularization * Y # initialize gradient as a regularization term\n",
    "    for u in range(n_users):\n",
    "        grad += fetch_neg_client_grad(matrix, X, Y, u, alpha) # add calculated gradient for a user\n",
    "    \n",
    "\n",
    "def fetch_neg_client_grad(matrix, X, Y, u, alpha):\n",
    "    '''\n",
    "    Fetches for entire item collection at once\n",
    "    f(u, i) = c_ui * (p_ui - yi^T xu) xu\n",
    "    f(u, Y) = C_u *  (p_u  -   Y xu ) xu^T = - (Y xu + (Cu-1)*(Yxu - pu)) xu^T\n",
    "    '''\n",
    "    indptr = matrix.indices # get indptr from sparse matrix\n",
    "    inds = matrix.indptr # get indices from sparse matrix\n",
    "    r = matrix.data # get ratings\n",
    "    \n",
    "    xu = X[u] # get user's vector  \n",
    "    user_neg_grad_val = ... # get negative gradient values for user \n",
    "    return # negative gradient values for user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 5, 4, ..., 4, 4, 5]),\n",
       " array([   0,  144,  253, ..., 3491, 3506, 3573], dtype=int32),\n",
       " array([     0,     51,    178, ..., 987669, 987790, 988129], dtype=int32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.data, data_matrix.indices, data_matrix.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.indptr[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.indices[178]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix[1, 101]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLyNcNyglLaB"
   },
   "source": [
    "## Client side\n",
    "\n",
    "Complete the functions to update user factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLoh5lDwlLaB"
   },
   "outputs": [],
   "source": [
    "def update_local_models(matrix, X, Y, regularization, alpha):\n",
    "    n_users, n_factors = X.shape\n",
    "    YtY = Y.T @ Y + regularization * np.eye(n_factors)\n",
    "    for u in range(n_users): # to imitate locally updating on the client side\n",
    "        X[u] = user_factor_update(Y, YtY, matrix, u, alpha) # each client does independently\n",
    "\n",
    "\n",
    "def user_factor_update(Y, YtY, matrix, u, alpha):\n",
    "    '''\n",
    "    Return the solution of equation\n",
    "    Xu = (YtCuY + regularization * I)^-1 (YtCuPu)\n",
    "    '''\n",
    "    A, b = solve_linear_equation(Y, YtY, matrix, u, alpha)\n",
    "    return # the solution of equation\n",
    "\n",
    "\n",
    "def solve_linear_equation(Y, YtY, matrix, u, alpha):\n",
    "    '''\n",
    "    Return A = YtCuY + regularization * I and b = YtCuPu\n",
    "    to use it later for solving the equation\n",
    "    Xu = (YtCuY + regularization * I)^-1 (YtCuPu)\n",
    "\n",
    "    Following identity might be helpful\n",
    "    YtCuY + regularization * I = YtY + regularization * I + Yt(Cu-I)Y\n",
    "    '''\n",
    "    indptr = ... # get indptr from sparse matrix \n",
    "    inds = ... # get indices from sparse matrix\n",
    "    r = ... # get ratings \n",
    "    \n",
    "    Ynnz = ... # get rated items factors \n",
    "    A = ... # accumulate YtCuY + regularization * I in A\n",
    "    b = ... # accumulate YtCuPu in b\n",
    "    return A, b  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AvisiIdlLaE"
   },
   "source": [
    "## Model Training\n",
    "Complete the function to build model. Choose the hyper-parameters and store it in config. Train your model on chosen hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmublXbnlLaH"
   },
   "outputs": [],
   "source": [
    "def build_model(model_config, trainset, trainset_description):\n",
    "    train_matrix = ... # get sparse matrix\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    user_factors = ... # initialize user factors\n",
    "    item_factors = ... # initialize user factors\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        ... # in each epoch update global model and then update local models\n",
    "            \n",
    "    return user_factors, item_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvWK56jAlXK0"
   },
   "outputs": [],
   "source": [
    "# create config with the following hyper parameters:\n",
    "# seed, n_factors, regularization, gain, alpha, n_epochs, n_iter.\n",
    "config = {...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4prUYPFlLaI"
   },
   "outputs": [],
   "source": [
    "params= build_model(config, train_data, data_description) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gczc3SRolMj2"
   },
   "source": [
    "# 3. Evaluation (5 pts)\n",
    "\n",
    "Complete the functions to predict relevance scores. Using predcted scores generate top-n recommendations. Evaluate quality of recommendations and report HR@5 and MRR@5 etrics. Remember that we don't want to recommend items from the user's history. You are recommended to use functions from the previous seminars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd6eGwAZR0-0"
   },
   "outputs": [],
   "source": [
    "topn = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrdPK2uElMj5"
   },
   "outputs": [],
   "source": [
    "# Complete model scoring function to predict relevance scores for test user-item pairs.\n",
    "def model_scoring(model_params, testset, testset_description):\n",
    "    user_factors, item_factors = ... # get user and item factros\n",
    "    test_user_factors = ... # get user factros for test users\n",
    "    scores = ... # get scores   \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B52qdo9dn0lk"
   },
   "outputs": [],
   "source": [
    "# Complete model recommendations function to generate top-n recommendations using predcted scores.\n",
    "def model_recom_func(model_scores, topn=5):\n",
    "    ...\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwMrJffjlMj4"
   },
   "outputs": [],
   "source": [
    "# Complete function to evaluate quality of recommendations\n",
    "def evaluate_func(model_recoms, holdout, holdout_description, topn=5):\n",
    "    ...\n",
    "    return hr, mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-u1a1EklMj8"
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qePo0RPJgZuF"
   },
   "outputs": [],
   "source": [
    "userid = data_description['users']\n",
    "seen_idx_mask = train_data[userid].isin(data_description['test_users'])\n",
    "testset = train_data[seen_idx_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVZ024YL63At"
   },
   "outputs": [],
   "source": [
    "test_scores = ... # get scores\n",
    "recoms = ... # get recommended items\n",
    "hr, mrr = ... # get metrics\n",
    "print(f'HR@{topn} = {hr:.4f}')\n",
    "print(f'MRR@{topn} = {mrr:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9uyF_hNlMj9"
   },
   "source": [
    "# Quick check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyVFXYPaa4Ez"
   },
   "source": [
    "Compare your model with one or two baselines and report the results. You can use code from previous seminars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5YC-DgsxVmb"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gC1tDoCRphSn"
   },
   "source": [
    "# 4. Hyper-parameter selection (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67Nl3qEePGRI"
   },
   "source": [
    "Complete the function to tune hyper-parameters of your model to provide the best quality. Train the model with the best hyper-parameters and report HR and MRR on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3lJ-FtzZdR7"
   },
   "outputs": [],
   "source": [
    "# you are free to change hp values\n",
    "params_dict = dict(n_factors = [10, 20, 50, 100],\n",
    "                  regularization = np.linspace(1, 5, 5).astype(int),\n",
    "                  gain = np.logspace(-4, -2, 5),\n",
    "                  alpha = np.linspace(1, 5, 5).astype(int),\n",
    "                  n_epochs = [10, 15, 20, 25],\n",
    "                  n_iter = np.linspace(4, 20, 5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK8C2t5auWHS"
   },
   "outputs": [],
   "source": [
    "param_grid, param_names = random_grid(params_dict, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiDxZxgBCfJ4"
   },
   "outputs": [],
   "source": [
    "def hp_selection(data, description, param_grid, param_names, testset, test_data):\n",
    "    ''' Return best HR value and best set of hyperparameters '''\n",
    "    ...\n",
    "    return best_hr, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcGdB4EQIEJz"
   },
   "outputs": [],
   "source": [
    "best_hr, best_params = hp_selection(train_data, data_description, param_grid, param_names, testset, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awIFVI1xcV--"
   },
   "outputs": [],
   "source": [
    "# Train the model with the best hyper-parameters and report HR and MRR on test dataset.\n",
    "hr, mrr = ...\n",
    "print(f'HR@{topn} = {hr:.4f}')\n",
    "print(f'MRR@{topn} = {mrr:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wknmnyX8dddN"
   },
   "source": [
    "# 5. Analysis (5 pts) \n",
    "\n",
    "Examine how the loss function, $||X||$ and $||Y||$ change during the training. Complete the function to obtain the history of losses values, $||X||$ and $||Y||$ for every epoch. Use best hyper-parameters for model config. Plot the graphs and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZZqPDUtcT-Y"
   },
   "outputs": [],
   "source": [
    "def model_analysis(model_config, trainset, trainset_description):\n",
    "    ...    \n",
    "    return X_norms, Y_norms, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwVRCq9Lc8cn"
   },
   "outputs": [],
   "source": [
    "X_norms, Y_norms, losses = model_analysis(best_params, train_data, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxV6mSMyDFZG"
   },
   "outputs": [],
   "source": [
    "# Plot the graphs and discuss the results.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18cbYM8m3FR9"
   },
   "source": [
    "What is the time complexity of the federated collaborative filterng with gradient descent? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkfLyJ0edHNA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "interpreter": {
   "hash": "1ba68f285e1c31cfa79ad3009fb16746741280f775149535e5b791f214db1c3e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
